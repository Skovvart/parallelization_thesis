% !TeX root = ../thesis.tex
\begin{abstract}
Parallelization can provide great performance boosts for large-scale independent numerical computations, for example in the field of insurance reserve estimation.
NVIDIA's CUDA platform allows for utilization of the parallelization power of the Graphic Processing Unit (GPU), but development is typically done using the CUDA C language which is based on the somewhat archaic C and C++ languages.
Industry would also benefit from being able to utilize the power of the GPU on modern platforms such as Microsoft's .NET.

This thesis investigates the benefits of transforming a single-threaded insurance reserve estimator to utilize parallelization on the GPU on the CUDA platform.
A base-line implementation is done in CUDA C and is then ported to the newer F\# language with the aid of the language integrated compiler Alea.cuBase and the performance implications are explored.
The F\# solution is further enhanced with the capability of parsing insurance plans written in Actulus CalcSpec that are automatically transformed into F\# Alea.cuBase GPU code. The performance implications of this is also explored.

The thesis concludes that software such as insurance reserve estimators can greatly benefit from parallelization on the GPU and that the benefits of developing on a modern platform such as F\# far outweigh the costs.
The parallelized version is up to 2400 times faster than the single-threaded version allowing for many more variations of the insurance plans.
It is also discovered that GPU code automatically transformed from calculation specifications barely have any negative consequences on performance or expressiveness.

\keywords{GPU Parallelization, Language Transformation, Insurance Reserve Estimation, F\# Alea.cuBase, Actulus CalcSpec, CUDA C}
\end{abstract}