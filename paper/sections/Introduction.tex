% !TeX root = ../thesis.tex
\section{Introduction}
As Central Processing Unit (CPU) clock-rate growth has mostly stagnated in recent times due partially to power inefficiency\cite{ross2008cpu}, parallelization is seen as one of primary techniques for increasing computational performance.

While parallelization can be utilized by multi-core CPUs, General Purpose Graphics Processing Units (GPGPU's) in particular are used when computations on large amounts of data is needed. Despite originating from the Graphics Processing Unit (GPU) designed for performing calculations in relation to computer graphics, the parallel computing architecture is very useful in domains besides computer graphics.

Parallelization is especially useful for large amounts of independent calculations that can be found in financial fields such as banking or insurance.

One approach to GPGPU programming is using the Compute Unified Device Architecture (CUDA) platform by NVIDIA, which is available to most platforms, but does require an NVIDIA graphics card.
The CUDA platform supports multiple languages, including Python and Fortran, but one of the most popular languages used is NVIDIA's CUDA C which is based on the somewhat archaic C and C++ languages.

In this thesis a single-threaded C\# insurance reserve estimator will be translated to the CUDA platform and parallelized and the performance ramifications will be discovered.
First a base-line implementation will be done in CUDA C and later a solution will be implemented on the more modern .NET platform in the F\# language using the language-integrated compiler Alea.cuBase to explore the effect on performance.
If there is no significant loss of performance, this could allow for all the benefits of modern languages while also allowing GPU code to be incorporated on the .NET platform.

%utilizing GPGPU parallelization as well as allowing it to be incorporated in a .NET work-flow.

The thesis will also cover how insurance plans specified in the Actulus Calculation Specification language (CalcSpec) will be automatically translated to code that will run on the GPU, and the performance ramifications of this will be analysed.

\subsection{Reading guide}
This thesis paper is targeted at people interested in high performance and parallel computing as well as people interested in language transformation. Some experience with programming, especially imperative, can be considered a requirement to fully understand everything. A general idea of overall computer architecture will also be very useful. Uncommon concepts will be explained to the best of my ability. Experience with a variant of C and a functional language (such as F\#, an ML variant or any other) should lead to little trouble following the paper.
%I need to know how to refer to the report and project. Do I use paper for the report? Project for the... well, project? Do I call everything a thesis

Subjects will be described in various levels of detail depending on their relevance to the main topics of the thesis.
This means that certain technologies, languages and paradigms will be described in less detail than strictly required background information and solution descriptions.

The thesis is structured into the following chapters.
The first chapter will introduce the thesis, including the motivation, the scope, approach and method used.

The second chapter will cover the required background information including the math used, the technologies utilized and the hardware the code has been tested on.

The third chapter will cover descriptions of the various implemented solutions, starting with the initial single-threaded C\# solution, followed by a CUDA C implementation. This is followed by a solution manually written in F\# using the language integrated compiler Alea.cuBase.

The fourth chapter will describe how pension plan specifications written in Actulus CalcSpec are parsed and transformed to F\#/Alea.cuBase GPU code and the performance ramifications of this.

The fifth chapter will discuss how various alterations to the project affected performance and discuss their viability. These alterations include adding customer and pension plan variables, various memory types and the order of execution and various optimization strategies are attempted.

The sixth chapter will discuss similarities and differences to related work.

Finally, the seventh chapter will conclude the thesis.