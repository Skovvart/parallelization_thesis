% !TeX root = ../thesis.tex
\subsection{F\# Alea.cuBase Solution}
The F\# Alea.cuBase solution has many similarities to the CUDA C implementation.
One key factor is that the Runge-Kutta 4 kernel is implemented using Code Quotations, as are the plan-specific $dV$ and $bj\_ii$ methods.
As the plan-specific $dV$ and $bj\_ii$ typically refer to helper-methods, you would often define them in terms of Quotations and use the splicing operators to mix them together.
This is possible, but F\# also allows one to use the \textit{[\textless{}ReflectedDefinition\textgreater{}]} attribute on method calls to make most regular methods accessible in Quotations.
An example of this can be seen in code sample \ref{cubase_pureendowment}. 
The various plans are in this case not implemented using classes, so each method name is prepended with a plan acronym ($pe\_$).
It also refers to come common constants and methods not defined in the class, much like the previous implementations.

\begin{lstlisting}[language=FSharp, caption=The pure endowment insurance plan expressed in F\# Alea.cuBase, label=cubase_pureendowment]
[<ReflectedDefinition>] 
let pe_b_0 t = zero
[<ReflectedDefinition>]
let pe_mu_01 t = GM t
[<ReflectedDefinition>]
let pe_bj_00 t = if t = pensiontime then bpension else zero
[<ReflectedDefinition>]
let pe_bj_01 t = zero
let pe_dV = 
	<@ fun t (V:deviceptr<floatP>) (res:deviceptr<floatP>) -> 
		res.[0] <- r t * V.[0] - pe_b_0 t - pe_mu_01 t * (zero - V.[0] + pe_bj_01 t) @>
let pe_bj_ii = 
	<@ fun t (res:deviceptr<floatP>) ->
		res.[0] <- pe_bj_00 t @>
\end{lstlisting}

To run the plan there is one Runge-Kutta 4 kernel defined as can partially be seen in code sample \ref{cubase_rk4_n_snippet}. For the full implementation see appendix \ref{app:cubase_rk4_n}
What may be of interest is the $deviceptr$ type used by $Va$ and $result$, which function very similarly to pointers in C.
The temporary arrays may also be of interest. They are simply initiated using Alea.cuBase and then transformed into $deviceptr$'s themselves.

\begin{lstlisting}[language=FSharp, caption=The Runge-Kutta 4 solver expressed in F\# Alea.cuBase, label=cubase_rk4_n_snippet]
let RK4_n dV bj_ii states = cuda {
	let! kernel =
		<@ fun a b steps (Va:deviceptr<floatP>) (result:deviceptr<floatP>) ->
			//Calculate unique result offset
			let offset = (blockIdx.x * blockDim.x + threadIdx.x) * states * (a + 1)
            
			//Splice in other quotation expressions
			let dV = %dV
			let bj_ii = %bj_ii
			let limConv = %limConv //different limits for float and double

			let h   = -one / conv steps
			//Initialize reusable intermediary arrays
			let k1	  = __local__.Array<floatP>(states) |> __array_to_ptr
			let k2	  = __local__.Array<floatP>(states) |> __array_to_ptr
			let k3	  = __local__.Array<floatP>(states) |> __array_to_ptr
			let k4	  = __local__.Array<floatP>(states) |> __array_to_ptr
			let tmp	  = __local__.Array<floatP>(states) |> __array_to_ptr
			let v	  = __local__.Array<floatP>(states) |> __array_to_ptr
            
            ...Actual Runge-Kutta 4 implementation
        @> |> Compiler.DefineKernel 

    return Entry(fun program ->
        let worker = program.Worker
        let kernel = program.Apply kernel
        fun a b steps ->
            //Calculate size of result array
            let n = (a + 1) * states * blocks * threads
			//Allocate memory on device
            use Va = worker.Malloc(Array.zeroCreate<floatP> states)
            use result = worker.Malloc(Array.zeroCreate<floatP> n)

            let lp = LaunchParam (blocks, threads)
            ...Timing mechanism start
            //Launch kernel with parameters
            kernel.Launch lp a b steps Va.Ptr result.Ptr
            ...Timing mechanism end, save kernel execution time in ms
            //Gather and return device results and kernel execution time
            let result = result.Gather()
            result, ms
        )
}
\end{lstlisting}

As the CUDA code is generated at runtime, a lot of the compile-time-limitations of CUDA disappear.
While the kernels may not take all types of parameters at launch-time, during kernel-compilation they can generally be used.
The code is not making much use of the functional paradigm and memory-allocation for the device is still required, but lots of small changes like the $use$ keyword still make it faster and safer to program in F\# as opposed to CUDA C.

The solution also makes use of a method to compile the kernels for future use and another to execute them, as can be seen in code sample \ref{cubase_compileandrun}. 

\begin{lstlisting}[language=FSharp, caption=Kernel compilation and execution methods in F\# Alea.cuBase, label=cubase_compileandrun]
let compile dV bj_ii states = RK4_n dV bj_ii states |> Compiler.load Worker.Default

let runKernel (program:Program<int->int->int->floatP[]*float>) a b = program.Run a b steps
\end{lstlisting}

The results of running the F\# Alea.cuBase solution shows that the highest number of calculations per ms were xx.xx for float precision or xx.xx ms for double precisions.
This is about identical to the CUDA C solution for floats but almost twice as fast for doubles.
The results were identical to the CUDA C solutions. For more information on result comparison see section \ref{subsec:result_comparison}.

other todo: 
	Add RK4\_n step-image like other reports? 
	show visual abstract syntax tree? 
	write more about delta-function (how it is a bad idea numerically, bj\_ii instead)



\subsection{Insurance plan parameters}
Talk about how running the same thing over and over again is not a very good idea, and how user and pension plan parameters are handled and their effect on performance.

Changed the dV, bj\_ii and RK4\_n signatures to include params array, setting old constants to variable number.

Talk about parameter generation and division of work (or wait until calcspec? dunno)